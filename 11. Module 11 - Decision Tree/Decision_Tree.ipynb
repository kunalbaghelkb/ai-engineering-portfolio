{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###1. What is a Decision Tree, and how does it work?\n",
        "A Decision Tree is a tree-structured model that splits data based on feature conditions to make predictions."
      ],
      "metadata": {
        "id": "AMa2nOOxB7Rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. What are impurity measures in Decision Trees?\n",
        "They quantify how mixed the classes are in a node (e.g., Gini, Entropy)."
      ],
      "metadata": {
        "id": "blWuf-uLB7TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. What is the mathematical formula for Gini Impurity?\n",
        "Gini = 1 - Σ(Pi^2), where pᵢ is the class probability."
      ],
      "metadata": {
        "id": "-TziA99rB7U1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. What is the mathematical formula for Entropy?\n",
        "Entropy = −Σ(pi logbase2 pi)."
      ],
      "metadata": {
        "id": "YkK7UXagB7Wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. What is Information Gain, and how is it used in Decision Trees?\n",
        "Information Gain measures impurity reduction after a split and selects the best split."
      ],
      "metadata": {
        "id": "6aH3H6dTB7YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. What is the difference between Gini Impurity and Entropy?\n",
        "Gini is faster to compute; Entropy is more sensitive to class distribution changes."
      ],
      "metadata": {
        "id": "SzcSthW8B7Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. What is the mathematical explanation behind Decision Trees?\n",
        "They recursively split data to minimize impurity using greedy optimization."
      ],
      "metadata": {
        "id": "uvoOqGT7B7bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. What is Pre-Pruning in Decision Trees?\n",
        "Stopping tree growth early using constraints like max depth or min samples."
      ],
      "metadata": {
        "id": "VnVnDQpEB7dK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. What is Post-Pruning in Decision Trees?\n",
        "Growing a full tree first, then trimming nodes to reduce overfitting."
      ],
      "metadata": {
        "id": "1YSmAZ3vB7e_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. What is the difference between Pre-Pruning and Post-Pruning?\n",
        "Pre-pruning stops early; post-pruning simplifies after full growth."
      ],
      "metadata": {
        "id": "YrMRN2T6B7gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11. What is a Decision Tree Regressor?\n",
        "It predicts continuous values by minimizing variance or MSE at splits."
      ],
      "metadata": {
        "id": "RcqGNIwZB7iH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###12. What are the advantages and disadvantages of Decision Trees?\n",
        "Advantages: interpretable, non-linear; Disadvantages: overfitting, instability."
      ],
      "metadata": {
        "id": "eIo6isEQB7j8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13. How does a Decision Tree handle missing values?\n",
        "By surrogate splits, imputation, or treating missing as a separate category."
      ],
      "metadata": {
        "id": "fndkYf1fB7lw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14. How does a Decision Tree handle categorical features?\n",
        "By splitting categories into subsets or using one-hot encoding."
      ],
      "metadata": {
        "id": "I9AAmP5OCWQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15. What are some real-world applications of Decision Trees?\n",
        "Credit scoring, medical diagnosis, fraud detection, and customer segmentation."
      ],
      "metadata": {
        "id": "n98xWOp7CWTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#16 - Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(accuracy_score(y_test, model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7y7_FmSCcug",
        "outputId": "2769594c-dfb7-42b0-d7df-5ae5a829dac3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17 - Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances.\n",
        "\n",
        "model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "model.fit(X_train, y_train)\n",
        "print(model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNfVxdkSCcw1",
        "outputId": "8b0f86a4-49e3-4de1-d185-e938e1e0dd54"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.01251826 0.         0.54371341 0.44376833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18 - Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy.\n",
        "\n",
        "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "print(accuracy_score(y_test, model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOWUnvD5Ccy4",
        "outputId": "0428f2ad-617a-4e2e-83c1-df08166ae65a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19 - Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "print(mean_squared_error(y_test, reg.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_ub9rs8Cc1y",
        "outputId": "ea3b8ce3-b5f9-4f63-cd7a-7797cb0ffe29"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5386784218839923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20 - Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz.\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor, export_text\n",
        "\n",
        "model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(export_text(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hfruLnNCc3n",
        "outputId": "2c6fe159-2613-4d68-b90e-580013e409f1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- feature_0 <= 5.08\n",
            "|   |--- feature_0 <= 3.13\n",
            "|   |   |--- feature_2 <= 4.34\n",
            "|   |   |   |--- value: [1.63]\n",
            "|   |   |--- feature_2 >  4.34\n",
            "|   |   |   |--- value: [1.17]\n",
            "|   |--- feature_0 >  3.13\n",
            "|   |   |--- feature_5 <= 2.40\n",
            "|   |   |   |--- value: [2.81]\n",
            "|   |   |--- feature_5 >  2.40\n",
            "|   |   |   |--- value: [1.88]\n",
            "|--- feature_0 >  5.08\n",
            "|   |--- feature_0 <= 6.82\n",
            "|   |   |--- feature_5 <= 2.60\n",
            "|   |   |   |--- value: [3.57]\n",
            "|   |   |--- feature_5 >  2.60\n",
            "|   |   |   |--- value: [2.66]\n",
            "|   |--- feature_0 >  6.82\n",
            "|   |   |--- feature_0 <= 7.82\n",
            "|   |   |   |--- value: [3.77]\n",
            "|   |   |--- feature_0 >  7.82\n",
            "|   |   |   |--- value: [4.59]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21 - Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree.\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "shallow = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "deep = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "shallow.fit(X_train, y_train)\n",
        "deep.fit(X_train, y_train)\n",
        "\n",
        "print(mean_squared_error(y_test, shallow.predict(X_test)))\n",
        "print(mean_squared_error(y_test, deep.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REKQDg8XCc59",
        "outputId": "821d5f1f-dd9d-4d8b-c9af-6a939782f264"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6307597519882218\n",
            "0.5428222185932364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22 - Write a Python program to train a Decision Tree Classifier using min _samples_split=5 and compare its accuracy with a default tree.\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "tree1 = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "tree2 = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "tree1.fit(X_train, y_train)\n",
        "tree2.fit(X_train, y_train)\n",
        "\n",
        "print(mean_squared_error(y_test, tree1.predict(X_test)))\n",
        "print(mean_squared_error(y_test, tree2.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfp-BHfCc8h",
        "outputId": "a581b017-46a7-403a-9abd-b183894405e9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5015045684027168\n",
            "0.5428222185932364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23 - Write a Python program to apply feature scaling before training a Decision Tree Regressor and compare performance.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "mse_unscaled = mean_squared_error(y_test, model.predict(X_test))\n",
        "\n",
        "model.fit(X_train_s, y_train)\n",
        "mse_scaled = mean_squared_error(y_test, model.predict(X_test_s))\n",
        "\n",
        "print(mse_unscaled)\n",
        "print(mse_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkVGX63Cc-Y",
        "outputId": "2a2d7cb4-f2e6-4c50-a436-0646c1ed6644"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5428222185932364\n",
            "0.5424849617443798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24 - Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "ovr = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr.fit(X_train, y_train)\n",
        "\n",
        "print(accuracy_score(y_test, ovr.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1FVuCRPCdBN",
        "outputId": "f504cecb-d933-4e78-e572-693cc9284e5f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25 - Write a Python program to train a Decision Tree Regressor and display feature importance scores.\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM_0grCYCdDn",
        "outputId": "70cb89fa-f562-4363-ef9a-1895f0ebb165"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.00843971 0.95248255 0.03907774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26 - Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree.\n",
        "\n",
        "reg1 = DecisionTreeRegressor(max_depth=5)\n",
        "reg2 = DecisionTreeRegressor()\n",
        "\n",
        "reg1.fit(X_train, y_train)\n",
        "reg2.fit(X_train, y_train)\n",
        "\n",
        "print(mean_squared_error(y_test, reg1.predict(X_test)))\n",
        "print(mean_squared_error(y_test, reg2.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iRKWdzsCslG",
        "outputId": "f259b728-a0e4-479b-988d-e3fe0aaf0f4e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27 - Write a Python program to train a Decision Tree Regressor, apply Cost Complexity Pruning (CCP), and evaluate performance.\n",
        "\n",
        "path = DecisionTreeRegressor(random_state=42).cost_complexity_pruning_path(X_train, y_train)\n",
        "alphas = path.ccp_alphas[:5]\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "for a in alphas:\n",
        "    reg = DecisionTreeRegressor(ccp_alpha=a, random_state=42)\n",
        "    reg.fit(X_train, y_train)\n",
        "    print(mean_squared_error(y_test, reg.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwREjSohCsrm",
        "outputId": "66033308-5259-4943-af2d-c914e72ae4a3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.00029931972789115435\n",
            "0.00029931972789115435\n",
            "0.00863265306122449\n",
            "0.008827442445203061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28 - Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxatbUe1Cs3T",
        "outputId": "49a51a01-863b-410a-df96-3abd0969492e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29 - Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "5OJYPyPICs_x",
        "outputId": "e59717b5-731b-4444-c251-2de9edfcd178"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30 - Write a Python program to use GridSearchCV to find optimal Decision Tree Regressor parameters.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "params = {\n",
        "    \"max_depth\": [3, 5, None],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    params,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(grid.best_params_)\n",
        "print(-grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBHy9ThfCtEU",
        "outputId": "f6307e64-c1dc-4df7-fdc8-9febd0fc7305"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 3, 'min_samples_split': 2}\n",
            "0.05741628327801709\n"
          ]
        }
      ]
    }
  ]
}